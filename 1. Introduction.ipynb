{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Ici nous allons utiliser tensorflow pour la premiere fois afin de classer des chiffres \"MNIST\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans le code qui suit nous allons charger les donnees MNIST, le code se chargera de telecharger les donnees pour vous, laissez lui un peu de temps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXyrK+KWijF8q6v8BQRG9jBkMPI8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x23959ffc9b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "s = ax.imshow(random.choice(mnist.test.images).reshape((28,28)), cmap = matplotlib.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ci-dessus un exemple aleatoire de chiffre MNIST. Le code a peu d'interet, ne vous attardez pas dessus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 28*28])\n",
    "classes = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos images font 28x28 pixels, nous avons donc besoin d'un moyen de donner ces images a notre modele, comme nous ne les envoyons pas au modele pendant que nous le construisons nous utilisons un **placeholder**.\n",
    "\n",
    "Nous utilisons egalement un **placeholder** pour les classes. Par exemple un chiffre '1' aura pour classe [1, 0, 0, 0, 0, 0, 0, 0, 0, 0] et le chiffre '5' aura pour classe [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], c'est pourquoi nous avons 10 comme dimension. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.zeros([28*28, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voila le modele, nous utilisons 10 neurones, 1 par chiffre possible, chaque neurone prend en entree tous les pixels nous avons donc besoin d'une matrice 28x28 = 784, 784x10.\n",
    "\n",
    "La variable b est notre bias, nous reviendrons sur son utilite dans un prochain chapitre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = tf.matmul(x, W) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous multiplions x qui etait notre placeholder de dimension Nx784 avec notre matrice W de dimension 784x10 ce qui donne une matrice Nx10 a laquelle nous ajoutons notre bias. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(\n",
    "      tf.nn.softmax_cross_entropy_with_logits(labels=classes, logits=y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici nous definissons notre fonction de cout, elle applique egalement la fonction **softmax** sur **y**.\n",
    "\n",
    "La fonction **softmax**:\n",
    "![softmax](https://static1.squarespace.com/static/54d1b23de4b0bce5ca12450e/t/5757319c0442623f70722a0b/1465332170338/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "entrainement = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous utilisons la methode de descente de gradient pour minimiser notre fonction de cout. \n",
    "\n",
    "![descente de gradient](http://images.slideplayer.fr/4/1570133/slides/slide_97.jpg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notre modele etant fini nous pouvons lancer une session tensorflow et initialiser toutes nos variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for _ in range(1000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    sess.run(entrainement, feed_dict={x: batch_xs, classes: batch_ys})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taux de reussite: 0.9189\n"
     ]
    }
   ],
   "source": [
    "# Test trained model\n",
    "prediction = tf.equal(tf.argmax(y, 1), tf.argmax(classes, 1))\n",
    "performance = tf.reduce_mean(tf.cast(prediction, tf.float32))\n",
    "taux_reussite = sess.run(performance, feed_dict={x: mnist.test.images,\n",
    "                                  classes: mnist.test.labels})\n",
    "\n",
    "print(\"Taux de reussite: \" + str(taux_reussite))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voila qui conclu l'introduction!\n",
    "\n",
    "**Exercice:** Utiliser la fonction prediction sur une image aleatoire random.choice(mnist.test.images) et l'afficher afin de verifier si vous etes d'accord avec la prediction du modele."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
