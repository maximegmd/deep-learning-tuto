{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Autoencoder\n",
    "\n",
    "Les autoencoders permettent d'extraire les caracteristiques importantes de donnees, le principe est tres simple, on demande a un multilayer perceptron de reconstituer l'entree, en utilisant un encodeur puis un decodeur.\n",
    "\n",
    "Le reseau autoencoder se retrouve sous la forme suivante:\n",
    "\n",
    "![autoencoder](http://nghiaho.com/wp-content/uploads/2012/12/autoencoder_network1.png)\n",
    "\n",
    "Vous noterez qu'il y a de moins en moins de neurones au centre et qu'il y a le meme nombre d'entree et de sortie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import MINST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parametres\n",
    "vitesse_apprentissage = 0.001\n",
    "batch_size = 256\n",
    "examples_to_show = 20\n",
    "\n",
    "# Parametres du reseau\n",
    "n_hidden_1 = 512 # Neurones de la premiere couche\n",
    "n_hidden_2 = 256 # Neurones de la secondes couche\n",
    "n_input = 28*28\n",
    "\n",
    "X = tf.placeholder(\"float\", [None, n_input])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_weights(x, y):\n",
    "    return tf.Variable(tf.truncated_normal([x, y], stddev=1./x))\n",
    "\n",
    "def generate_bias(x):\n",
    "    return tf.Variable(tf.truncated_normal([x], stddev=1./x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_W1 = generate_weights(n_input, n_hidden_1)\n",
    "encoder_W2 = generate_weights(n_hidden_1, n_hidden_2)\n",
    "decoder_W1 = generate_weights(n_hidden_2, n_hidden_1)\n",
    "decoder_W2 = generate_weights(n_hidden_1, n_input)\n",
    "\n",
    "encoder_b1 = generate_bias(n_hidden_1)\n",
    "encoder_b2 = generate_bias(n_hidden_2)\n",
    "decoder_b1 = generate_bias(n_hidden_1)\n",
    "decoder_b2 = generate_bias(n_input)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme il s'agit d'un multilayer perceptron que nous avons deja vu, je ne commente pas cette section, vous voyez seulement l'initialisation des poids et bias de chaque couche."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def encoder(x):\n",
    "    layer_1 = tf.nn.sigmoid(tf.matmul(x, encoder_W1) + encoder_b1)\n",
    "    layer_2 = tf.nn.sigmoid(tf.matmul(layer_1, encoder_W2) + encoder_b2)\n",
    "    return layer_2\n",
    "\n",
    "def decoder(x):\n",
    "    layer_1 = tf.nn.sigmoid(tf.matmul(x, decoder_W1) + decoder_b1)\n",
    "    layer_2 = tf.nn.sigmoid(tf.matmul(layer_1, decoder_W2) + decoder_b2)\n",
    "    return layer_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On introduit ici une nouvelle fonction **sigmoid**, nous avons vu par le passe **softmax** et **relu**, la fonction sigmoide a la forme suivante:\n",
    "\n",
    "![sigmoid](http://www.ai-junkie.com/ann/evolved/images/sigmoid.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encoder_op = encoder(X)\n",
    "decoder_op = decoder(encoder_op)\n",
    "\n",
    "y_pred = decoder_op\n",
    "\n",
    "cout = tf.reduce_mean(tf.pow(X - y_pred, 2))\n",
    "optimizer = tf.train.AdamOptimizer(vitesse_apprentissage).minimize(cout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le code ci-dessus ne devrait pas vous surprendre, vous noterez que j'ai choisi un autre algorithme d'optimisation car il est plus rapide, l'ancien algorithme fonctionnerait egalement, vous pouvez d'ailleurs l'essayer et voir les differences de performances. La fonction de cout est differente egalement, on compare pixel par pixel et on eleve au carre pour se debarasser du signe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0001 cout = 0.067301281\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(init)\n",
    "\n",
    "total_batch = int(mnist.train.num_examples/batch_size)\n",
    "\n",
    "for epoch in range(20):\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        _, c = sess.run([optimizer, cout], feed_dict={X: batch_xs})\n",
    "    \n",
    "    print(\"Iteration:\", '%04d' % (epoch+1),\n",
    "              \"cout =\", \"{:.9f}\".format(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encode_decode = sess.run(y_pred, feed_dict={X: mnist.test.images[:examples_to_show]})\n",
    "\n",
    "# Comparaison entre l'entree et la sortie\n",
    "f, a = plt.subplots(2, examples_to_show, figsize=(examples_to_show, 2))\n",
    "for i in range(examples_to_show):\n",
    "    a[0][i].imshow(np.reshape(mnist.test.images[i], (28, 28)))\n",
    "    a[1][i].imshow(np.reshape(encode_decode[i], (28, 28)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice 1:** Connecter encoder_op a un reseau utilise precedement pour faire la detection de chiffre et voir le resultat.\n",
    "\n",
    "**Exercice 2:** Ajouter une couche avec une dimension encore plus petite et regarder le resultat du decodage, que se passe t-il ?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
